#!/usr/bin/python3.6
#This script uses the data produced by "single_mice_selector.py" and "RCDNN_training_data_generator" to generate 
#training data which is used to train a recurrent convolutional deconvolutional artificial neural network.
#The RCDNN will be able to seperated overlapping mice after it is trained with the data produced by this script.
#To generate this training set sequences of single mouse moving around in the cage are overlapped.
#This way it is possible to know where one mice starts and another mice ends.

#torch libaries
from torchvision import transforms,datasets
import torch, torchvision, torch.optim as optim, torch.nn as nn, torch.nn.functional as F
#general libaries
from tqdm  import tqdm
import matplotlib.pyplot as plt, cv2
import numpy as np, sys, os, cv2, random, math, time
#own libaries
import net_handler as nh, data_manipulater as dm, image_analyser as ia

#used to proper dislpay an image with opencv
def lucidDreaming(wait=True):
    while 1:
        k = cv2.waitKey(30) & 0xff
        if k == 27:
            #print('keyboard interuption: its getting dark')
            return True
        if k == 32:
            return False
        if not wait:
            return False

#load single mice data generated by "single_mice_selector.py"
X_pre = np.load('X_pre_sep.npy',allow_pickle=True)
print(X_pre.shape)
print(X_pre[0].shape)
y_pre = np.load('y_pre_sep.npy',allow_pickle=True)
index_pre_seperator = np.load('index_pre_seperator.npy')

#data is the list where best matching sequences are saved
data = list()
print('find matching sequences')
#pick first stack or sequence of images from X_pre and y_pre
for d1,start1,end1 in index_pre_seperator:
    start1 = int(start1)
    end1 = int(end1)
    X_stack1 = X_pre[start1:end1]
    y_stack1 = y_pre[start1:end1]
    #length of first stack
    l1 = end1-start1+1
    #pick second stack or sequence of images from X_pre and y_pre
    for d2,start2,end2 in index_pre_seperator:
        start2 = int(start2)
        end2 = int(end2)
        #first stack is equal to second stack skip
        if start1 != start2:
            X_stack2 = X_pre[start2:end2]
            y_stack2 = y_pre[start2:end2]
            #length of second stack
            l2 = end2-start2+1
            #if the first stack is longer than the second stack they will be compared.
            #this way each stack will only be once comapred to each other stack.
            #if this condition would not be in place each stack would be compared twice with each other stack
            if l1 > l2:
                #normal_max holds the maximum overlapp of the two compared stacks
                normal_max = 0
                #slid_max holds the index of the maxium overlap
                slid_max = 0
                #since the sequence are not necessary of the same length one sequence is slid over the other one and the position of the highest overlap is saved
                for slide in range(0,l1-l2+1,15):
                    intersection = np.clip(y_stack1[slide:slide+l2-1],0,1)*np.clip(y_stack2,0,1)
                    normal = np.sum(intersection)/np.prod(y_stack2.shape)*1000
                    if normal > normal_max:
                        slide_max = slide
                        normal_max = normal
                #saved best matching slide
                data.append([normal_max,start1+slide_max,start1+slide_max+l2,start2,end2])
            print(len(data),l1,l2,l1>l2)
        #else:
        #    print(d1)
    print('next')
        

#the data is soted after the highest overlapping sequences and afterwards it is saved
tmp = data.copy()
tmp = sorted(tmp)
tmp.reverse()
np.save('Data_Sep_Sorted_plus_small_distance.npy', tmp)

#the data can be loaded to skip previous steps if they were already executed
tmp = np.load('Data_Sep_Sorted_plus_small_distance.npy')
print(len(tmp))

#at this point the best matching sequences are overlapped to generated the training data for the RCDNN
#init variables
print('overlapping mice')
index = 0
dim = (128,128)
padding = 30
index_stack = 0
X = list()
y = list()
#start using the best overlapping sequences and move down the rabbit hole
for _,start1,end1,start2,end2 in tmp:
    start1 = int(start1)
    end1 = int(end1)
    start2 = int(start2)
    end2 = int(end2)
    #if the overlapp is smaller than 0.1 break
    if _ < 0.1:
        break
    #select both statcks
    X_stack1 = X_pre[start1:end1]
    y_stack1 = y_pre[start1:end1]
    X_stack2 = X_pre[start2:end2]
    y_stack2 = y_pre[start2:end2]
    
    #both cases are used.
    #this for loop determines which mice is infront and which is back
    for _ in range(2):
        #create stacks to save overlapping mice data
        current_stack_X1 = list()
        current_stack_y1 = list()
        current_stack_X2 = list()
        current_stack_y2 = list()
        
        #iterates over each element in both stacks
        for img1,img2,bin1,bin2 in zip(X_stack1,X_stack2,y_stack1,y_stack2):
            #determines if mice are overlapping or not
            add = False

            #gets the contours from both binary images from each stack
            cnts = ia.filtered_contours(bin1)
            cnts += ia.filtered_contours(bin2)
            
            #if mice are overlapping change add to true
            if np.count_nonzero(cv2.bitwise_and(bin1,bin2)) > 0:
                add = True

            #use eroision on binary images to remove edge between mice and cage
            bin1 = cv2.erode(bin1,ia.get_kernel(12))
            bin2 = cv2.erode(bin2,ia.get_kernel(12))
            
            #apply new binary to image and change image from color to grayscale
            img1 = cv2.bitwise_and(img1,img1,mask = bin1)
            img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)
            img2 = cv2.bitwise_and(img2,img2,mask = bin2)
            img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)

            #remove part of the mouse in the back which is overlapping with the mice in the front and add both images together
            img2 = cv2.bitwise_and(img2,img2,mask = cv2.bitwise_not(bin1))
            img_c = img1+img2
            
            #apply histogramm equalization
            img_c = cv2.equalizeHist(img_c)
            
            #get the close up image of both overlapping mice
            cnt1 = ia.get_max_contour(bin1)
            cnt2 = ia.get_max_contour(bin2)
            img_c1, bb1 = ia.get_fragment(img_c,cnt1)
            img_c2, bb2 = ia.get_fragment(img_c,cnt2)
            
            #create a combined binary image
            bin_g1 = bin1
            bin_g2 = bin2
            bin_c = np.stack((bin_g1,bin_g2),axis=2)

            #get the same close up image of the binary iamge
            bin_c1, bb1 = ia.get_fragment(bin_c,cnt1)
            bin_c2, bb2 = ia.get_fragment(bin_c,cnt2)
            
            #reshape into consistent shape
            img_c1 = cv2.resize(img_c1, dim, interpolation = cv2.INTER_AREA)
            bin_c1 = cv2.resize(bin_c1, dim, interpolation = cv2.INTER_AREA)
            img_c2 = cv2.resize(img_c2, dim, interpolation = cv2.INTER_AREA)
            bin_c2 = cv2.resize(bin_c2, dim, interpolation = cv2.INTER_AREA)

            #if the mice are overlapping add em to the storage stacks
            if add:
                current_stack_X1.append(img_c1)
                current_stack_y1.append(bin_c1)
                current_stack_X2.append(img_c2)
                current_stack_y2.append(bin_c2)
            
        #if the mice are overlapped for at least 100 frames add them to the traning data for the RCDNN
        t = 100
        if len(current_stack_X1) >= t:
            X.append(dm.opencv_to_pytorch(np.array(current_stack_X1[0:t:1])))
            y.append(dm.opencv_to_pytorch(np.array(current_stack_y1[0:t:1])))
            X.append(dm.opencv_to_pytorch(np.array(current_stack_X2[0:t:1])))
            y.append(dm.opencv_to_pytorch(np.array(current_stack_y2[0:t:1])))
        
        #change which mice is infront and which is in the back
        X_stack_tmp = X_stack1
        y_stack_tmp = y_stack1
        X_stack1 = X_stack2
        y_stack1 = y_stack2
        X_stack2 = X_stack_tmp
        y_stack2 = y_stack_tmp
    print(len(X),len(y))

    index += 1
print(len(X),len(y))

#shuffle traninig data
random.seed(1)
random.shuffle(X)
random.seed(1)
random.shuffle(y)

#formate traningdata to numpy array
X = np.array(X)
y = np.array(y)
print(X.shape,y.shape)

#save traning data
np.save('X_sep_rcdnn.npy',X)
np.save('y_sep_rcdnn.npy',y)